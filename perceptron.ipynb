{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Multiclass Kernel Perceptrons\n",
    "IDs: <> and <>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Perceptron Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassKernelPerceptron():\n",
    "    \"\"\"\n",
    "    A multiclass implementation of the kernel perceptron\n",
    "    Designed for the MNIST dataset to classify digits 0-9\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, kernel, num_digits=10):\n",
    "        \"\"\"\n",
    "        Instantiates the perceptron instance\n",
    "\n",
    "        Args:\n",
    "            kernel: kernel function to use\n",
    "            num_digits: optional param- number of digits to classify,\n",
    "                assumes digits range from 0...num_digits\n",
    "        \"\"\"\n",
    "        self.kernel = kernel\n",
    "        self.num_classes = num_digits\n",
    "\n",
    "    def train(self, X, Y, kernel_matrix=None, epochs=10):   \n",
    "        \"\"\"\n",
    "        Trains the perceptron\n",
    "\n",
    "        Args:\n",
    "            X: training data (n x d)\n",
    "            Y: training labels (n x 1)\n",
    "            kernel_matrix: optional pre-calculated kernel matrix\n",
    "            epochs: number of epochs to run\n",
    "        \"\"\"\n",
    "        self.X_training = X\n",
    "        Y = Y.astype(int)\n",
    "\n",
    "        # Calculate gram matrix if necessary\n",
    "        if kernel_matrix is not None:\n",
    "            self.gram_matrix = kernel_matrix\n",
    "        else: \n",
    "            self.gram_matrix = self.get_kernel_matrix(self.kernel, X)\n",
    "\n",
    "        self.alpha = self.update_alpha(self.gram_matrix, Y, self.num_classes, epochs)\n",
    "    \n",
    "    # Pulling this into a separate function for numba,\n",
    "    #   but consider this as if it were appended to the train method\n",
    "    @staticmethod\n",
    "    @jit(nopython=True)\n",
    "    def update_alpha(gram_matrix, Y, num_classes, epochs):\n",
    "        \n",
    "        num_data = gram_matrix.shape[0]\n",
    "        alpha = np.zeros((num_data, num_classes), dtype=np.float32)\n",
    "\n",
    "        # To boost efficiency, let's keep track of non-zero alpha weights\n",
    "        # Note that a data index is nontrivial if its alpha is nonzero for ANY perceptron\n",
    "        nontrivial_indices = np.empty(num_data, dtype=np.int32)\n",
    "        cur_nontrivial_idx = 0\n",
    "\n",
    "        # Instantiate once and reuse in update step\n",
    "        label_vector = -1 * np.ones(num_classes, dtype=np.float32)\n",
    "        zeros = np.zeros(num_classes, dtype=np.float32)\n",
    "        decisions = np.sign(zeros)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            for i in range(num_data):\n",
    "                # Get decisions for all the classifiers\n",
    "                if (cur_nontrivial_idx > 0):\n",
    "                    # Pull out the relevant values of alpha and the gram matrix\n",
    "                    data_to_consider = nontrivial_indices[:cur_nontrivial_idx]\n",
    "                    decisions = np.sign(np.dot(\n",
    "                        alpha[data_to_consider].T,\n",
    "                        gram_matrix[:, i][data_to_consider]\n",
    "                    ))\n",
    "\n",
    "                # The label vector should be -1 for every index\n",
    "                # except the one corresponding to the current Yi label\n",
    "                label_vector[Y[i]] = 1\n",
    "\n",
    "                # For a given classifier, if the decision * label <= 0,\n",
    "                # the update is the label, otherwise it is zero\n",
    "                update = np.where(decisions*label_vector <=0, label_vector, zeros)\n",
    "\n",
    "                # Add the update to alpha, reset label vector\n",
    "                if (np.any(update != 0) and not np.any(alpha[i,:] != 0)):\n",
    "                    nontrivial_indices[cur_nontrivial_idx] = i\n",
    "                    cur_nontrivial_idx += 1\n",
    "\n",
    "                alpha[i,:] += update\n",
    "                label_vector[Y[i]] = -1\n",
    "        \n",
    "        return alpha\n",
    "                \n",
    "    def predict(self, X, kernel_matrix=None):\n",
    "        \"\"\"\n",
    "        Predicts the labels of a new set of data\n",
    "\n",
    "        Args:\n",
    "            X: data to classify\n",
    "            kernel_matrix: an optional parameter for a precalculated kernel\n",
    "                between X and the training data\n",
    "        \"\"\"\n",
    "        # If we need to compute a kernel matrix, we only need to find distances\n",
    "        #   where the alphas are not 0.\n",
    "        relevant_indices = np.where(np.sum(self.alpha != 0, axis=1) > 0)[0]\n",
    "        if kernel_matrix is None:\n",
    "            kernel_matrix = self.get_kernel_matrix(self.kernel, X, self.X_training[relevant_indices])\n",
    "        else: \n",
    "            kernel_matrix = kernel_matrix[:, :][:, relevant_indices]\n",
    "        \n",
    "        alpha = self.alpha[relevant_indices]\n",
    "\n",
    "        # See how confident each classifier is that a given point is in that class\n",
    "        #   i.e. the distance between the point and the decision boundary\n",
    "        # We want to get a N x K matrix where N = number of classifiers, K = num data in X\n",
    "        # Each value is given by the dot product of the alphas for the classifier\n",
    "        #   and the distances from the data point to the training examples\n",
    "        data_confidence_by_classifier = kernel_matrix @ alpha\n",
    "        \n",
    "        # Pick the label of the classifier with the max confidence\n",
    "        # Each classifier operates on a 1-v-All basis\n",
    "        predictions = np.argmax(data_confidence_by_classifier, axis=1)\n",
    "        return predictions\n",
    "    \n",
    "    @staticmethod\n",
    "    @jit(nopython=True)\n",
    "    def get_kernel_matrix(kernel_func, X1, X2=None):\n",
    "        \"\"\"\n",
    "        Calculates the full kernel matrix between X1 and X2\n",
    "        using an input kernel function\n",
    "\n",
    "        Args:\n",
    "            kernel_func: kernel function\n",
    "            X1: Ax1 vector\n",
    "            X2: optional Bx1 vector\n",
    "        Returns:\n",
    "            (AxB) matrix of kernel distances if X2 is given\n",
    "            (AxA) matrix otherwise\n",
    "        \"\"\"\n",
    "        A = X1.shape[0]\n",
    "        if X2 is None:\n",
    "            # In one-matrix case, we can use symmetry\n",
    "            kernel_matrix = np.empty((A,A), dtype=np.float32)\n",
    "            for i in range(A):\n",
    "                for j in range(i,A):\n",
    "                    kernel_matrix[i, j] = kernel_func(X1[i], X1[j])\n",
    "                    kernel_matrix[j, i] = kernel_matrix[i, j]\n",
    "        else:\n",
    "            B = X2.shape[0]\n",
    "            kernel_matrix = np.empty((A,B), dtype=np.float32)\n",
    "            for i in range(A):\n",
    "                for j in range(B):\n",
    "                    kernel_matrix[i, j] = kernel_func(X1[i], X2[j])\n",
    "        return kernel_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_fraction):\n",
    "    \"\"\"\n",
    "    Splits the data into two sets with the specified fraction.\n",
    "\n",
    "    Args:\n",
    "        data: numpy matrix of data\n",
    "        split_fraction: fraction to split\n",
    "    Returns:\n",
    "        larger dataset, smaller dataset, shuffled indices, and split index\n",
    "    \"\"\"\n",
    "    num_data = data.shape[0]\n",
    "    indices = np.arange(num_data)\n",
    "    np.random.shuffle(indices)\n",
    "    shuffled_data = data[indices]\n",
    "\n",
    "    split_index = int(num_data * split_fraction)\n",
    "    return shuffled_data[:split_index], shuffled_data[split_index:], indices, split_index\n",
    "\n",
    "def get_cross_validation_indices(data, num_folds):\n",
    "    \"\"\"\n",
    "    Gets the indices of the data that represent a cross-validation split\n",
    "\n",
    "    Args:\n",
    "        data: numpy matrix of data\n",
    "        num_folds: number of folds\n",
    "    Returns:\n",
    "        list of (start, end) tuples\n",
    "    \"\"\"\n",
    "    num_data = data.shape[0]\n",
    "    data_per_fold = int(num_data / num_folds)\n",
    "\n",
    "    start = 0\n",
    "    index_tuples = []\n",
    "    for _ in range(num_folds-1):\n",
    "        index_tuples.append((start, start + data_per_fold))\n",
    "        start += data_per_fold\n",
    "    \n",
    "    index_tuples.append((start, num_data))\n",
    "    return index_tuples\n",
    "\n",
    "def get_data_and_labels(data):\n",
    "    \"\"\"\n",
    "    Splits the data from the labels\n",
    "\n",
    "    Args:\n",
    "        data: numpy matrix of data\n",
    "    Returns:\n",
    "        data, labels\n",
    "    \"\"\"\n",
    "    return data[:,1:], data[:,0]\n",
    "\n",
    "def calculate_accuracy(predictions, actual):\n",
    "    \"\"\"\n",
    "    Returns predicted accuracy\n",
    "\n",
    "    Args:\n",
    "        predictions: numpy array of predictions\n",
    "        actual: actual values\n",
    "    Returns:\n",
    "        accuracy float\n",
    "    \"\"\"\n",
    "    num_correct = np.sum(predictions == actual)\n",
    "    return num_correct / actual.shape[0]\n",
    "\n",
    "def get_polynomial_kernel(degree):\n",
    "    \"\"\"\n",
    "    Returns a polynomial kernel with specified degree\n",
    "\n",
    "    Args:\n",
    "        degree: degree of polynomial\n",
    "    Returns:\n",
    "        polynomial kernel function\n",
    "    \"\"\"\n",
    "    @jit(nopython=True)\n",
    "    def polynomial_kernel(x1, x2):\n",
    "        return (np.dot(x1, x2)) ** degree\n",
    "    \n",
    "    return polynomial_kernel\n",
    "\n",
    "def split_kernels(kernel, split_index):\n",
    "    \"\"\"\n",
    "    Returns a training and test kernel from an index to split\n",
    "\n",
    "    Args:\n",
    "        kernel: NxN gram matrix\n",
    "        split_index: index < N, number of training examples\n",
    "    Returns:\n",
    "        training kernel matrix (square), test kernel matrix (rectangle)\n",
    "    \"\"\"\n",
    "    # Grab the first split_index elements for the square training kernel\n",
    "    #   and one of the remaining rectangles for the test kernel \n",
    "    training = kernel[:split_index,:split_index]\n",
    "    test = kernel[split_index:,:split_index]\n",
    "    return training, test\n",
    "\n",
    "def get_training_validation_kernels(kernel, start, end):\n",
    "    \"\"\"\n",
    "    Returns a training and validation kernel from cross-validation indices\n",
    "    The start-end defines the validation region\n",
    "\n",
    "    Args:\n",
    "        kernel: NxN gram matrix\n",
    "        start, end: indices < N of the validation region\n",
    "    Returns:\n",
    "        training kernel matrix (square), validation kernel matrix (rectangle)\n",
    "    \"\"\"\n",
    "    # Build training array by picturing four corners of a square\n",
    "    left = np.vstack((kernel[:start,:start], kernel[end:,:start]))\n",
    "    right = np.vstack((kernel[:start,end:], kernel[end:,end:]))\n",
    "    training = np.hstack((left, right))\n",
    "\n",
    "    # Build validation array by picturing a rectangle\n",
    "    valid = np.hstack((kernel[start:end, :start], kernel[start:end, end:]))\n",
    "    return training, valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: Basic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into numpy\n",
    "data = np.genfromtxt('./zipcombo.dat')\n",
    "\n",
    "# Define polynomial perceptrons, pre-calculate kernels\n",
    "poly_perceptrons = [MultiClassKernelPerceptron(get_polynomial_kernel(d+1)) for d in range(7)]\n",
    "poly_kernels = [p.get_kernel_matrix(p.kernel, data) for p in poly_perceptrons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running iter 0\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 1\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 2\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 3\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 4\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 5\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 6\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 7\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 8\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 9\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 10\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 11\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 12\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 13\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 14\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 15\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 16\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 17\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 18\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n",
      "Currently running iter 19\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "> Perceptron 5\n",
      "> Perceptron 6\n"
     ]
    }
   ],
   "source": [
    "def run_20_iters(perceptrons, kernels):\n",
    "    \"\"\"\n",
    "    Follows the routine in Q1 of the coursework: \n",
    "        Reports the best accuracy of the perceptrons over 20 iterations\n",
    "\n",
    "    Args:\n",
    "        perceptrons: perceptrons to use\n",
    "        kernels: pre-calculated kernels corresponding to the perceptrons\n",
    "    Returns:\n",
    "        accuracy stats for the 20 runs for each perceptron\n",
    "    \"\"\"\n",
    "        \n",
    "    stats = [[] for _ in range(len(perceptrons))]\n",
    "    for iter in range(20):\n",
    "        print(\"Currently running iter\", iter)\n",
    "        training, test, shuffle_indices, split_index = split_data(data, 0.8)\n",
    "        train_X, train_Y = get_data_and_labels(training)\n",
    "        test_X, test_Y = get_data_and_labels(test)\n",
    "\n",
    "        for i, perceptron in enumerate(perceptrons):\n",
    "            print(\"> Perceptron\", i)\n",
    "            shuffled_kernel = kernels[i][shuffle_indices, :][:, shuffle_indices]\n",
    "            training_kernel, test_kernel = split_kernels(shuffled_kernel, split_index)\n",
    "\n",
    "            perceptron.train(train_X, train_Y, training_kernel)\n",
    "            predictions = perceptron.predict(test_X, test_kernel)\n",
    "            accuracy = calculate_accuracy(predictions, test_Y)\n",
    "            stats[i].append(accuracy)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "q1_stats = run_20_iters(poly_perceptrons, poly_kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy by kernel degree\n",
      "0.9466, 0.9618\n",
      "0.9804, 0.9862\n",
      "0.9823, 0.9877\n",
      "0.9841, 0.9886\n",
      "0.9829, 0.9872\n",
      "0.9812, 0.9871\n",
      "0.9807, 0.9856\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics!\n",
    "def get_confidence_range(arr):\n",
    "    mean = np.mean(arr)\n",
    "    std = np.std(arr)\n",
    "    return [mean-std, mean+std]\n",
    "\n",
    "def pretty_print_stat(arr):\n",
    "    print(\", \".join([\"{:.4f}\".format(elm) for elm in arr]))\n",
    "\n",
    "q1_summary = [get_confidence_range(runs) for runs in q1_stats]\n",
    "\n",
    "print(\"Test accuracy by kernel degree\")\n",
    "for stat in q1_summary:\n",
    "    pretty_print_stat(stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running iter 0\n",
      "> Cross-validation (0, 1487)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "> Cross-validation (1487, 2974)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "> Cross-validation (2974, 4461)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "> Cross-validation (4461, 5948)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "> Cross-validation (5948, 7438)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "Currently running iter 1\n",
      "> Cross-validation (0, 1487)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "> Cross-validation (1487, 2974)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "> Cross-validation (2974, 4461)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "> Cross-validation (4461, 5948)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "> Cross-validation (5948, 7438)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "Currently running iter 2\n",
      "> Cross-validation (0, 1487)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "> Cross-validation (1487, 2974)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "> Cross-validation (2974, 4461)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "> Cross-validation (4461, 5948)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n",
      "> Cross-validation (5948, 7438)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      ">> Perceptron 5\n",
      ">> Perceptron 6\n"
     ]
    }
   ],
   "source": [
    "def run_cv_20_iters(perceptrons, kernels, confusion_stats=None):\n",
    "    \"\"\"\n",
    "    Follows the routine in Q2 of the coursework: \n",
    "        Performs 5-fold CV to find the optimal hyperparameter\n",
    "        Optionally outputs confusion stats\n",
    "\n",
    "    Args:\n",
    "        perceptrons: perceptrons to use\n",
    "        kernels: pre-calculated kernels corresponding to the perceptrons\n",
    "        confusion_stats: optional array to store confusion stats\n",
    "    Returns:\n",
    "        average accuracy, degree for the different runs\n",
    "    \"\"\"\n",
    "    accuracy_stats = []\n",
    "    best_degrees = []\n",
    "\n",
    "    for iter in range(3):\n",
    "        print(\"Currently running iter\", iter)\n",
    "        training, test, shuffle_indices, split_index = split_data(data, 0.8)\n",
    "        test_X, test_Y = get_data_and_labels(test)\n",
    "        full_train_X, full_train_Y = get_data_and_labels(training)\n",
    "\n",
    "        # Cross-Validation step\n",
    "        num_folds = 5\n",
    "        cv_indices = get_cross_validation_indices(training, num_folds)\n",
    "\n",
    "        # Pre-calculate kernel matrices\n",
    "        shuffled_kernels = [split_kernels(k[shuffle_indices, :][:, shuffle_indices], split_index) for k in kernels]\n",
    "        cv_accuracies = [[] for _ in perceptrons]\n",
    "        \n",
    "        # Iterate through CV sets\n",
    "        for cur_idx in cv_indices:\n",
    "            print(\"> Cross-validation\", cur_idx)\n",
    "            start, end = cur_idx\n",
    "            cur_valid = training[start:end,:]\n",
    "            cur_train = np.concatenate((training[:start,:], training[end:,:]))\n",
    "\n",
    "            train_X, train_Y = get_data_and_labels(cur_train)\n",
    "            valid_X, valid_Y = get_data_and_labels(cur_valid)\n",
    "\n",
    "            # For each set, evaluate each perceptron\n",
    "            for i, perceptron in enumerate(perceptrons):\n",
    "                print(\">> Perceptron\", i)\n",
    "                # Grab the training kernel of the i'th shuffled kernel\n",
    "                full_training_kernel = shuffled_kernels[i][0]\n",
    "                training_kernel, validation_kernel = get_training_validation_kernels(full_training_kernel, start, end)\n",
    "                perceptron.train(train_X, train_Y, training_kernel)\n",
    "                predictions = perceptron.predict(valid_X, validation_kernel)\n",
    "\n",
    "                accuracy = calculate_accuracy(predictions, valid_Y)\n",
    "                cv_accuracies[i].append(accuracy)\n",
    "        \n",
    "        # Choose the best perceptron, use it to train the whole set\n",
    "        best_perceptron = np.argmax(np.mean(cv_accuracies, axis=1))\n",
    "        best_degrees.append(best_perceptron + 1)\n",
    "\n",
    "        # Leverage pre-computed kernel matrix\n",
    "        training_kernel, test_kernel = shuffled_kernels[best_perceptron]\n",
    "\n",
    "        chosen_perceptron = perceptrons[best_perceptron]\n",
    "        chosen_perceptron.train(full_train_X,full_train_Y,training_kernel)\n",
    "        test_predictions = chosen_perceptron.predict(test_X, test_kernel)\n",
    "        test_accuracy = calculate_accuracy(test_predictions, test_Y)\n",
    "        accuracy_stats.append(test_accuracy)\n",
    "\n",
    "        if confusion_stats is not None:\n",
    "            confusion_stats.append((test_X, test_Y, test_predictions))\n",
    "\n",
    "    return accuracy_stats, best_degrees\n",
    "\n",
    "q3_confusion_stats = []\n",
    "q2_stats, q2_ds = run_cv_20_iters(poly_perceptrons, poly_kernels, q3_confusion_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated accuracy\n",
      "0.9830, 0.9847\n",
      "Cross-validated degrees\n",
      "3.8619, 4.8047\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics!\n",
    "q2_summary_accuracies = get_confidence_range(q2_stats)\n",
    "q2_summary_degrees = get_confidence_range(q2_ds)\n",
    "\n",
    "print(\"Cross-validated accuracy\")\n",
    "pretty_print_stat(q2_summary_accuracies)\n",
    "print(\"Cross-validated degrees\")\n",
    "pretty_print_stat(q2_summary_degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3: Confusion Matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000, 0.0000, 0.0044, 0.0021, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000\n",
      "0.0000, 0.0000, 0.0026, 0.0000, 0.0013, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000\n",
      "0.0018, 0.0018, 0.0000, 0.0090, 0.0037, 0.0000, 0.0018, 0.0000, 0.0019, 0.0000\n",
      "0.0021, 0.0022, 0.0083, 0.0000, 0.0022, 0.0145, 0.0000, 0.0021, 0.0000, 0.0000\n",
      "0.0000, 0.0041, 0.0080, 0.0000, 0.0000, 0.0041, 0.0060, 0.0000, 0.0020, 0.0000\n",
      "0.0023, 0.0022, 0.0028, 0.0067, 0.0045, 0.0000, 0.0028, 0.0000, 0.0023, 0.0000\n",
      "0.0017, 0.0022, 0.0000, 0.0000, 0.0055, 0.0057, 0.0000, 0.0000, 0.0022, 0.0000\n",
      "0.0000, 0.0000, 0.0000, 0.0019, 0.0038, 0.0022, 0.0000, 0.0000, 0.0058, 0.0020\n",
      "0.0000, 0.0026, 0.0000, 0.0000, 0.0000, 0.0000, 0.0046, 0.0067, 0.0000, 0.0146\n",
      "0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0083, 0.0000\n"
     ]
    }
   ],
   "source": [
    "def calc_confusion_stats(confusion_stat):\n",
    "    test_X, test_Y, preds = confusion_stat\n",
    "\n",
    "    digits, counts = np.unique(test_Y, return_counts=True)\n",
    "    confusion_matrix = np.zeros((10, 10))\n",
    "\n",
    "\n",
    "    for i, y in enumerate(test_Y.astype(int)):\n",
    "        if (y != preds[i]):\n",
    "            confusion_matrix[y, preds[i]] += 1\n",
    "    \n",
    "    # Divide each row by count of that digit\n",
    "    normalized_confusion_matrix = confusion_matrix / counts.reshape(-1, 1)\n",
    "    return normalized_confusion_matrix\n",
    "\n",
    "test_q3_stats = np.array([calc_confusion_stats(stat) for stat in q3_confusion_stats])\n",
    "mean_confusion_matrix = np.mean(test_q3_stats, axis=0)\n",
    "\n",
    "foo = [pretty_print_stat(row) for row in mean_confusion_matrix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4: Mistaken digits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_params(params):\n",
    "    plt.figure()\n",
    "    plt.imshow(np.reshape(params, (16,16)), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "visualize_params(data[0,1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian Kernels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in cs:\n",
    "#     p_tst = MultiClassKernelPerceptron(get_gaussian_kernel(c))\n",
    "#     xtr, ytr = get_data_and_labels(data[:5000,:])\n",
    "#     p_tst.train(xtr, ytr)\n",
    "#     xtst, ytst = get_data_and_labels(data[5000:6000,:])\n",
    "#     y_hat = p_tst.predict(xtst)\n",
    "#     print(\">\", c)\n",
    "#     print(np.sum(y_hat == ytst)/y_hat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaussian_kernel(c):\n",
    "    \"\"\"\n",
    "    Returns a Gaussian kernel with specified width\n",
    "\n",
    "    Args:\n",
    "        c: inverse width of gaussian kernel\n",
    "    Returns:\n",
    "        gaussian kernel function\n",
    "    \"\"\"\n",
    "    @jit(nopython=True)\n",
    "    def gaussian_kernel(p, q):\n",
    "        return np.exp(-c * np.sum((p - q) ** 2))\n",
    "    \n",
    "    return gaussian_kernel\n",
    "\n",
    "cs = np.linspace(0.004, 0.020, 5)\n",
    "gaussian_perceptrons = [MultiClassKernelPerceptron(get_gaussian_kernel(c)) for c in cs]\n",
    "gaussian_kernels = [p.get_kernel_matrix(p.kernel, data) for p in gaussian_perceptrons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running iter 0\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 1\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 2\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 3\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 4\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 5\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 6\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 7\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 8\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 9\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 10\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 11\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 12\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 13\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 14\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 15\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 16\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 17\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 18\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      "Currently running iter 19\n",
      "> Perceptron 0\n",
      "> Perceptron 1\n",
      "> Perceptron 2\n",
      "> Perceptron 3\n",
      "> Perceptron 4\n",
      ">>>\n",
      "Test accuracy by kernel degree\n",
      "0.9832, 0.9879\n",
      "0.9851, 0.9890\n",
      "0.9854, 0.9893\n",
      "0.9861, 0.9902\n",
      "0.9851, 0.9890\n"
     ]
    }
   ],
   "source": [
    "q5_stats = run_20_iters(gaussian_perceptrons, gaussian_kernels)\n",
    "q5_summary = [get_confidence_range(runs) for runs in q5_stats]\n",
    "\n",
    "print()\n",
    "print(\"Test accuracy by kernel degree\")\n",
    "for stat in q5_summary:\n",
    "    pretty_print_stat(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running iter 0\n",
      "> Cross-validation (0, 1487)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "> Cross-validation (1487, 2974)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "> Cross-validation (2974, 4461)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "> Cross-validation (4461, 5948)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "> Cross-validation (5948, 7438)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "Currently running iter 1\n",
      "> Cross-validation (0, 1487)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "> Cross-validation (1487, 2974)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "> Cross-validation (2974, 4461)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "> Cross-validation (4461, 5948)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "> Cross-validation (5948, 7438)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "Currently running iter 2\n",
      "> Cross-validation (0, 1487)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "> Cross-validation (1487, 2974)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "> Cross-validation (2974, 4461)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "> Cross-validation (4461, 5948)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "> Cross-validation (5948, 7438)\n",
      ">> Perceptron 0\n",
      ">> Perceptron 1\n",
      ">> Perceptron 2\n",
      ">> Perceptron 3\n",
      ">> Perceptron 4\n",
      "Cross-validated accuracy\n",
      "0.9819, 0.9880\n",
      "Cross-validated degrees\n",
      "2.8619, 3.8047\n"
     ]
    }
   ],
   "source": [
    "q5_cv_stats, q5_cv_cs = run_cv_20_iters(gaussian_perceptrons, gaussian_kernels)\n",
    "\n",
    "# Summary statistics!\n",
    "q5_cv_summary_accuracies = get_confidence_range(q5_cv_stats)\n",
    "q5_cv_summary_cs = get_confidence_range(q5_cv_cs)\n",
    "\n",
    "print()\n",
    "print(\"Cross-validated accuracy\")\n",
    "pretty_print_stat(q5_cv_summary_accuracies)\n",
    "print(\"Cross-validated degrees\")\n",
    "pretty_print_stat(q5_cv_summary_cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quesiton 6: All v All Multiclass Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
