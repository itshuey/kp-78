{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassKernelPerceptron():\n",
    "    \"\"\"\n",
    "    A multiclass implementation of the kernel perceptron\n",
    "    Designed for the MNIST dataset to classify digits 0-9\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, kernel, num_digits):\n",
    "        \"\"\"\n",
    "        Instantiates the perceptron instance\n",
    "\n",
    "        Args:\n",
    "            kernel: kernel function to use\n",
    "            num_diits: number of digits to classify,\n",
    "                assumes digits range from 0...num_digits\n",
    "        \"\"\"\n",
    "        self.kernel = kernel\n",
    "        self.num_classes = num_digits\n",
    "\n",
    "    def train(self, X, Y, gram_matrix = None):   \n",
    "        \"\"\"\n",
    "        Trains the perceptron\n",
    "\n",
    "        Args:\n",
    "            X: training data (n x d)\n",
    "            Y: training labels (n x 1)\n",
    "            gram_matrix: an optional pre-calculated gram matrix\n",
    "        \"\"\"\n",
    "        max_epochs = 50\n",
    "        num_data = X.shape[0]\n",
    "        self.alpha = np.zeros((num_data, self.num_classes))\n",
    "        self.X_training = X\n",
    "        Y = Y.astype(int)\n",
    "\n",
    "        # Instantiate once and reuse in update step\n",
    "        label_vector = -1 * np.ones(self.num_classes)\n",
    "        zeros = np.zeros(self.num_classes)\n",
    "\n",
    "        # Calculate gram matrix if not already provided\n",
    "        self.gram_matrix = gram_matrix or self.get_kernel_matrix(X, X)\n",
    "\n",
    "        for epoch in range(max_epochs):\n",
    "            for i in range(num_data):\n",
    "                # Get decisions for all the classifiers\n",
    "                decisions = np.sign(np.dot(self.alpha.T, self.gram_matrix[:, i]))\n",
    "\n",
    "                # The label vector should be -1 for every index\n",
    "                # except the one corresponding to the current Yi label\n",
    "                label_vector[Y[i]] = 1\n",
    "\n",
    "                # For a given classifier, if the decision * label <= 0,\n",
    "                # the update is the label, otherwise it is zero\n",
    "                update = np.where(decisions*label_vector <=0, label_vector, zeros)\n",
    "\n",
    "                # Add the update to alpha, reset label vector\n",
    "                self.alpha[i,:] += update\n",
    "                label_vector[Y[i]] = -1\n",
    "                \n",
    "    def predict(self, X, kernel_matrix = None):\n",
    "        \"\"\"\n",
    "        Predicts the labels of a new set of data\n",
    "\n",
    "        Args:\n",
    "            X: data to classify\n",
    "            kernel_matrix: an optional parameter for a precalculated kernel\n",
    "                between X and the training data\n",
    "        \"\"\"\n",
    "        # We only need to consider the data where the alphas are not all 0\n",
    "        relevant_indices = np.where(np.sum(self.alpha != 0, axis=1) > 0)[0]\n",
    "        # You can provide a precalculated kernel matrix\n",
    "        if kernel_matrix != None:\n",
    "            k_matrix = kernel_matrix[:,relevant_indices] \n",
    "        else: \n",
    "            k_matrix = self.get_kernel_matrix(X, self.X_training[relevant_indices])\n",
    "\n",
    "        # See how confident each classifier is that a given point is in that class\n",
    "        #   i.e. the distance between the point and the decision boundary\n",
    "        # We want to get a N x K matrix where N = number of classifiers, K = num data in X\n",
    "        # Each value is given by the dot product of the alphas for the classifier\n",
    "        #   and the distances from the data point to the training examples\n",
    "        data_confidence_by_classifier = self.alpha[relevant_indices].T @ k_matrix\n",
    "        \n",
    "        # Pick the label of the classifier with the max confidence\n",
    "        # Each classifier operates on a 1-v-All basis\n",
    "        predictions = np.argmax(data_confidence_by_classifier, axis=0)\n",
    "        return predictions\n",
    "    \n",
    "    def get_kernel_matrix(self, X1, X2):\n",
    "        \"\"\"\n",
    "        Calculates the full kernel matrix between X1 and X2\n",
    "        using the perceptron's kernel function\n",
    "\n",
    "        Args:\n",
    "            X1, X2: (ax1) and (bx1) vectors\n",
    "        Returns:\n",
    "            axb matrix of kernel distances\n",
    "        \"\"\"\n",
    "        return np.array([[\n",
    "            self.kernel(X1[i], X2[j])\n",
    "                for i in range(X1.shape[0])] \n",
    "                for j in range(X2.shape[0])])\n",
    "\n",
    "# === HELPER FUNCTIONS =============\n",
    "def split_data(data, split_fraction):\n",
    "    \"\"\"\n",
    "    Splits the data into two sets with the specified fraction.\n",
    "\n",
    "    Args:\n",
    "        data: numpy matrix of data\n",
    "        split_fraction: fraction to split\n",
    "    Returns:\n",
    "        larger dataset, smaller dataset\n",
    "    \"\"\"\n",
    "    num_data = data.shape[0]\n",
    "    np.random.shuffle(data)\n",
    "    split_index = int(num_data - num_data * split_fraction)\n",
    "\n",
    "    return data[:split_index], data[split_index:]\n",
    "\n",
    "def get_polynomial_kernel(degree):\n",
    "    \"\"\"\n",
    "    Returns a polynomial kernel with specified degree\n",
    "\n",
    "    Args:\n",
    "        degree: degree of polynomial\n",
    "    Returns:\n",
    "        polynomial kernel function\n",
    "    \"\"\"\n",
    "    def polynomial_kernel(x1, x2):\n",
    "        return (np.dot(x1, x2)) ** degree\n",
    "    \n",
    "    return polynomial_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into numpy\n",
    "data = np.genfromtxt('./zipcombo.dat')\n",
    "\n",
    "# Adjust data labels to start from 0\n",
    "data[:,0] -= 1\n",
    "training, validation = split_data(data, 0.8)\n",
    "\n",
    "degree = 3\n",
    "num_classes = len(np.unique(data[:,0]))\n",
    "kperceptron = MultiClassKernelPerceptron(get_polynomial_kernel(degree), num_classes)\n",
    "\n",
    "train_X = training[:,1:]\n",
    "train_Y = training[:,0]\n",
    "kperceptron.train(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num correct 5860\n",
      "Ratio 0.7877402876730744\n"
     ]
    }
   ],
   "source": [
    "valid_X = validation[:,1:]\n",
    "valid_Y = validation[:,0].astype(int)\n",
    "\n",
    "predictions = kperceptron.predict(valid_X)\n",
    "# print(\"predictions:\", predictions)\n",
    "\n",
    "num_correct = (predictions == valid_Y).sum()\n",
    "ratio = num_correct / valid_X.shape[0]\n",
    "print(\"Num correct\", num_correct)\n",
    "print(\"Ratio\", ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   4    5    8 ... 1854 1856 1857]\n",
      "(1218, 10)\n"
     ]
    }
   ],
   "source": [
    "eval = np.zeros(10)\n",
    "idx = np.where(np.sum(kperceptron.alpha != 0, axis=1) == 0)[0]\n",
    "print(idx)\n",
    "print(kperceptron.alpha[idx].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_params(params):\n",
    "    plt.figure()\n",
    "    plt.imshow(np.reshape(params, (16,16)),\n",
    "                interpolation=\"None\",\n",
    "                cmap='gray',\n",
    "                vmin=0, \n",
    "                vmax=1)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "visualize_params(data[6,1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.genfromtxt('./zipcombo.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape\n",
    "np.unique(data1[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
